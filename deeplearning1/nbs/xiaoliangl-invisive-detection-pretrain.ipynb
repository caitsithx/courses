{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import math\n",
    "from glob import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import bcolz\n",
    "def save_array(fname, arr): c=bcolz.carray(arr, rootdir=fname, mode='w'); c.flush()\n",
    "def load_array(fname): return bcolz.open(fname)[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "def lr_schedule(epoch):\n",
    "    if epoch <= 50:\n",
    "        return 0.0001\n",
    "    else: \n",
    "        return 0.00005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd /home/caitsithx/courses/deeplearning1/nbs\n",
    "DATA_DIR = '/home/caitsithx/courses/deeplearning1/nbs/data/invasive-species-monitoring'\n",
    "TRAIN_DIR = DATA_DIR + '/train'\n",
    "RESULT_DIR = DATA_DIR + '/result'\n",
    "\n",
    "TRAIN_FEAT = RESULT_DIR + '/train_feats.dat'\n",
    "VAL_FEAT = RESULT_DIR + '/val_feats.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(DATA_DIR+'/train_labels.csv')\n",
    "master = df_train\n",
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = []\n",
    "file_paths = []\n",
    "for i in range(len(master)):\n",
    "    file_paths.append( TRAIN_DIR + '/' + str(master.ix[i][0]) +'.jpg' )\n",
    "    y.append(master.ix[i][1])\n",
    "y = np.array(y)\n",
    "print(y.shape)\n",
    "print(len(file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(file_paths[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#image reseize & centering & crop \n",
    "\n",
    "def centering_image(img):\n",
    "    size = [256,256]\n",
    "    \n",
    "    img_size = img.shape[:2]\n",
    "    \n",
    "    # centering\n",
    "    row = (size[1] - img_size[0]) // 2\n",
    "    col = (size[0] - img_size[1]) // 2\n",
    "    resized = np.zeros(list(size) + [img.shape[2]], dtype=np.uint8)\n",
    "    resized[row:(row + img.shape[0]), col:(col + img.shape[1])] = img\n",
    "\n",
    "    return resized\n",
    "\n",
    "\n",
    "x = []\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #resize\n",
    "    if(img.shape[0] > img.shape[1]):\n",
    "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "    else:\n",
    "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "\n",
    "    #centering\n",
    "    img = centering_image(cv2.resize(img, dsize=tile_size))\n",
    "    \n",
    "    #out put 224*224px \n",
    "    img = img[16:240, 16:240]\n",
    "    x.append(img)\n",
    "\n",
    "x = np.array(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = np.transpose(x, (0, 3, 1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(DATA_DIR+\"/sample_submission.csv\")\n",
    "img_path = DATA_DIR+\"/test/unknown/\"\n",
    "\n",
    "test_names = []\n",
    "file_paths = []\n",
    "\n",
    "for i in range(len(sample_submission)):\n",
    "    test_names.append(sample_submission.ix[i][0])\n",
    "    file_paths.append( img_path + str(int(sample_submission.ix[i][0])) +'.jpg' )\n",
    "    \n",
    "test_names = np.array(test_names)\n",
    "print(test_names.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images = []\n",
    "for file_path in file_paths:\n",
    "    #read image\n",
    "    img = cv2.imread(file_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    #resize\n",
    "    if(img.shape[0] > img.shape[1]):\n",
    "        tile_size = (int(img.shape[1]*256/img.shape[0]),256)\n",
    "    else:\n",
    "        tile_size = (256, int(img.shape[0]*256/img.shape[1]))\n",
    "\n",
    "    #centering\n",
    "    img = centering_image(cv2.resize(img, dsize=tile_size))\n",
    "    \n",
    "    #out put 224*224px \n",
    "    img = img[16:240, 16:240]\n",
    "    test_images.append(img)\n",
    "    \n",
    "    path, ext = os.path.splitext( os.path.basename(file_paths[0]) )\n",
    "\n",
    "test_images = np.array(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(test_images.shape)\n",
    "test_images = np.transpose(test_images, (0, 3, 1, 2))\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_array(DATA_DIR+ '/train_imges.npy', x)\n",
    "save_array(DATA_DIR+ '/test_imges.npy', test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train and val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = load_array(DATA_DIR+ '/train_imges.npy')\n",
    "test_images = load_array(DATA_DIR+ '/test_imges.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_num = len(y)\n",
    "random_index = np.random.permutation(data_num)\n",
    "\n",
    "x_shuffle = []\n",
    "y_shuffle = []\n",
    "for i in range(data_num):\n",
    "    x_shuffle.append(x[random_index[i]])\n",
    "    y_shuffle.append(y[random_index[i]])\n",
    "    \n",
    "x = np.array(x_shuffle) \n",
    "y = np.array(y_shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_split_num = int(round(0.2*len(y)))\n",
    "x_train = x[val_split_num:]\n",
    "y_train = y[val_split_num:]\n",
    "x_test = x[:val_split_num]\n",
    "y_test = y[:val_split_num]\n",
    "\n",
    "print('x_train', x_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('x_test', x_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model, load_model\n",
    "from keras import applications\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "img_rows, img_cols, img_channel = 224, 224, 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "incep_model = applications.InceptionV3(include_top=False, \n",
    "                                       weights='imagenet', \n",
    "                                       input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg16_model = applications.VGG16(weights='imagenet', \n",
    "                                 include_top=False, \n",
    "                                 input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg19_model = applications.VGG19(include_top=False, \n",
    "                                 weights='imagenet', \n",
    "                                 input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res_model = applications.ResNet50(\n",
    "            include_top=False, \n",
    "            weights='imagenet',\n",
    "            input_tensor=None, \n",
    "            input_shape=(img_rows, img_cols, img_channel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vgg19_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#base_model.output_shape[1:]\n",
    "def get_dense_model(input_shape):\n",
    "    dense_model = Sequential()\n",
    "    dense_model.add(Flatten(input_shape=input_shape))\n",
    "    \n",
    "    dense_model.add(Dense(256, activation='relu'))\n",
    "    dense_model.add(Dropout(0.25))\n",
    "    dense_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return dense_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(Model(inputs=vgg16_model.input, \n",
    "                    outputs=get_dense_model(vgg16_model.output_shape[1:])(vgg16_model.output)))\n",
    "models.append(Model(inputs=vgg19_model.input, \n",
    "                    outputs=get_dense_model(vgg19_model.output_shape[1:])(vgg19_model.output)))\n",
    "models.append(Model(inputs=res_model.input, \n",
    "                    outputs=get_dense_model(res_model.output_shape[1:])(res_model.output)))\n",
    "models.append(Model(inputs=incep_model.input, \n",
    "                    outputs=get_dense_model(incep_model.output_shape[1:])(incep_model.output)))\n",
    "\n",
    "for model in models:\n",
    "    model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "batch_size=40\n",
    "w_file = RESULT_DIR + '/xiaoliangl_id_{}.h5'\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        rotation_range=30, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1, \n",
    "        horizontal_flip=True)\n",
    "train_datagen.fit(x_train)\n",
    "vld_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_epochs=10\n",
    "\n",
    "for i, model in enumerate(models):\n",
    "    print (\"train model: %d \" % i)\n",
    "    model.fit_generator(\n",
    "        train_datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "        epochs=nb_epochs,\n",
    "        callbacks=[ModelCheckpoint(w_file.format(i), \n",
    "                                   monitor='val_acc', \n",
    "                                   save_best_only=True),\n",
    "                                   LearningRateScheduler(lr_schedule)],\n",
    "        validation_data=(x_test, y_test),\n",
    "        validation_steps=x_test.shape[0] // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = test_images.astype('float32')\n",
    "test_images /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i, model in enumerate(models):\n",
    "    model.load_weights(w_file.format(i))\n",
    "    pred = model.predict(test_images)\n",
    "    preds.append(pred)\n",
    "preds = np.mean(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = models[1].predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(DATA_DIR+\"/sample_submission.csv\")\n",
    "\n",
    "for i, name in enumerate(test_names):\n",
    "    sample_submission.loc[sample_submission['name'] == name, 'invasive'] = preds[i]\n",
    "\n",
    "sample_submission.to_csv(RESULT_DIR + \"/submit2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
